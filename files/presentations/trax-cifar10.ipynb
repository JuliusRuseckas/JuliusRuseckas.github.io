{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 classification using Trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Trax](https://trax-ml.readthedocs.io/en/latest/) is an end-to-end library for deep learning that focuses on clear code and speed. It is actively used and maintained in the [Google Brain team](https://research.google.com/teams/brain/).\n",
    "\n",
    "GitHub repo: https://github.com/google/trax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic units in Trax are *tensors*, using numpy interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Trax numpy operations are accelerated using GPU or TPU. The gradients of functions on tensors are automatically computed. This is done in the `trax.fastmath` package which supports two backends:\n",
    "- [JAX](https://github.com/google/jax)\n",
    "- [TensorFlow numpy](https://www.tensorflow.org/guide/tf_numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries on top of JAX:\n",
    "- [Flax](https://flax.readthedocs.io/en/latest/) (also by Google)\n",
    "- [Haiku](https://dm-haiku.readthedocs.io/en/latest/) (by Google [DeepMind](https://deepmind.com/))\n",
    "- [Elegy](https://poets-ai.github.io/elegy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing JAX: https://github.com/google/jax#pip-installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax import shapes\n",
    "from trax.fastmath import numpy as jnp\n",
    "from trax.supervised import training\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable GPU usage by TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current trax backend: jax\n"
     ]
    }
   ],
   "source": [
    "print(\"Current trax backend:\", trax.fastmath.backend_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU or TPU devices: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of CPU or TPU devices:\", trax.fastmath.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_STEPS = 20000\n",
    "STEPS_PER_CHECKPOINT = 1000\n",
    "EVAL_BATCHES = 300\n",
    "WARMUP_STEPS = 500\n",
    "MAX_LR = 1e-3\n",
    "OUTPUT_DIR = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img):\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 40, 40)\n",
    "    img = tf.image.random_crop(img, [32, 32, 3])\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    img = tf.image.random_saturation(img, 0.8, 1.2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augment(generator):\n",
    "    for imgs, tgts in generator:\n",
    "        for i in range(len(imgs)):\n",
    "            imgs[i] = augment_image(imgs[i])\n",
    "        yield (imgs, tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToFloat(generator):\n",
    "    for img, tgt in generator:\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        yield (img, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stream = trax.data.Serial(\n",
    "    trax.data.TFDS('cifar10', data_dir='data', keys=('image', 'label'), train=True),\n",
    "    trax.data.Shuffle(),\n",
    "    trax.data.Batch(BATCH_SIZE),\n",
    "    Augment,\n",
    "    ToFloat,\n",
    "    trax.data.AddLossWeights() # needed for tl.CrossEntropyLoss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stream = trax.data.Serial(\n",
    "    trax.data.TFDS('cifar10', data_dir='data', keys=('image', 'label'), train=False),\n",
    "    trax.data.Batch(BATCH_SIZE),\n",
    "    ToFloat,\n",
    "    trax.data.AddLossWeights()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test generator:\n",
    "batch = next(train_stream())\n",
    "img = batch[0][0]\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(filters, kernel_size=3, strides=1, act=True, mode='train'):\n",
    "    layers = [\n",
    "        tl.Conv(filters, (kernel_size, kernel_size), strides=(strides, strides), padding='SAME',\n",
    "                kernel_initializer=tl.initializers.KaimingNormalInitializer()),\n",
    "        tl.BatchNorm(mode=mode)\n",
    "    ]\n",
    "    if act: layers.append(tl.Relu())\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicResidual(res_filters, strides=1, mode='train'):\n",
    "    return [\n",
    "        ConvBlock(res_filters, strides=strides, mode=mode),\n",
    "        ConvBlock(res_filters, act=False, mode=mode)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Shortcut(prev_filters, res_filters, strides=1, mode='train'):\n",
    "    layers = []\n",
    "    if strides > 1:\n",
    "        layers.append(tl.AvgPool((strides, strides), (strides, strides)))\n",
    "    if prev_filters != res_filters:\n",
    "        layers += ConvBlock(res_filters, kernel_size=1, act=False, mode=mode)\n",
    "    if len(layers) == 0: layers = None\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZerosInitializer(shape, rng):\n",
    "    return jnp.zeros(shape, jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(prev_filters, res_filters, strides=1, mode='train'):\n",
    "    shortcut = Shortcut(prev_filters, res_filters, strides, mode=mode)\n",
    "    residual = [\n",
    "        BasicResidual(res_filters, strides, mode=mode),\n",
    "        tl.Weights(ZerosInitializer, shape=(1,)),\n",
    "        tl.Multiply()\n",
    "    ]\n",
    "    return [\n",
    "        tl.Residual(residual, shortcut=shortcut),\n",
    "        tl.Relu()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBody(filters, repetitions, strides, mode='train'):\n",
    "    layers = []\n",
    "    res_filters = filters\n",
    "    for rep, stride in zip(repetitions, strides):\n",
    "        for _ in range(rep):\n",
    "            layers.append(ResidualBlock(filters, res_filters, stride, mode=mode))\n",
    "            filters = res_filters\n",
    "            stride = 1\n",
    "        res_filters *= 2\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(filter_list, stride=1, mode='train'):\n",
    "    layers = []\n",
    "    for filters in filter_list:\n",
    "        layers.append(ConvBlock(filters, strides=stride, mode=mode))\n",
    "        stride = 1\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlobalAvgPool():\n",
    "    def pool(x):\n",
    "        pool_size = tuple(x.shape[1:3]) # NHWC\n",
    "        return trax.fastmath.avg_pool(x, pool_size=pool_size, strides=None, padding='VALID')\n",
    "    \n",
    "    return tl.Fn(\"GlobalAvgPool\", pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Head(classes, p_drop=0., mode='train'):\n",
    "    layers = [\n",
    "        GlobalAvgPool(),\n",
    "        tl.Flatten()\n",
    "    ]\n",
    "    if p_drop > 0: layers.append(tl.Dropout(p_drop, mode=mode))\n",
    "    layers += [\n",
    "        tl.Dense(classes),\n",
    "        tl.LogSoftmax()\n",
    "    ]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(repetitions, classes, strides=None, p_drop=0., mode='train'):\n",
    "    if not strides: strides = [2] * (len(repetitions) + 1)\n",
    "    return tl.Serial(\n",
    "        Stem([32, 32, 64], stride=strides[0], mode=mode),\n",
    "        ResidualBody(64, repetitions, strides[1:], mode=mode),\n",
    "        Head(classes, p_drop=p_drop, mode=mode)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(mode='train'):\n",
    "    return ResNet([2, 2, 2, 2], NUM_CLASSES, strides=[1, 1, 2, 2, 2], p_drop=0.3, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = MyModel(mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Conv\n",
       "  BatchNorm\n",
       "  Relu\n",
       "  Conv\n",
       "  BatchNorm\n",
       "  Relu\n",
       "  Conv\n",
       "  BatchNorm\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      [AvgPool(2,2), Conv, BatchNorm]\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      [AvgPool(2,2), Conv, BatchNorm]\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      [AvgPool(2,2), Conv, BatchNorm]\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Relu\n",
       "        Conv\n",
       "        BatchNorm\n",
       "        Weights_(1,)_in0\n",
       "        Multiply_in2\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Relu\n",
       "  GlobalAvgPool\n",
       "  Flatten_keep1\n",
       "  Dropout\n",
       "  Dense_10\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_stream(),\n",
    "    loss_layer=tl.CrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adam(),\n",
    "    lr_schedule=trax.supervised.lr_schedules.warmup_and_rsqrt_decay(WARMUP_STEPS, MAX_LR),\n",
    "    n_steps_per_checkpoint=STEPS_PER_CHECKPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_task = training.EvalTask(\n",
    "    labeled_data=eval_stream(),\n",
    "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "    n_eval_batches=EVAL_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiserver/.virtualenvs/deeplearning/lib/python3.6/site-packages/jax/_src/lax/lax.py:6081: UserWarning: Explicitly requested dtype <class 'jax._src.numpy.lax_numpy.int64'> requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  warnings.warn(msg.format(dtype, fun_name , truncated_dtype))\n"
     ]
    }
   ],
   "source": [
    "training_loop = training.Loop(\n",
    "    model,\n",
    "    train_task,\n",
    "    eval_model=eval_model,\n",
    "    eval_tasks=eval_task,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 11205746\n",
      "Step      1: Ran 1 train steps in 16.24 secs\n",
      "Step      1: train CrossEntropyLoss |  2.61132336\n",
      "Step      1: eval  CrossEntropyLoss |  10.20209974\n",
      "Step      1: eval          Accuracy |  0.10989583\n",
      "\n",
      "Step   1000: Ran 999 train steps in 116.09 secs\n",
      "Step   1000: train CrossEntropyLoss |  1.76638615\n",
      "Step   1000: eval  CrossEntropyLoss |  3.25688744\n",
      "Step   1000: eval          Accuracy |  0.18250000\n",
      "\n",
      "Step   2000: Ran 1000 train steps in 106.21 secs\n",
      "Step   2000: train CrossEntropyLoss |  1.18806684\n",
      "Step   2000: eval  CrossEntropyLoss |  1.69844913\n",
      "Step   2000: eval          Accuracy |  0.48614583\n",
      "\n",
      "Step   3000: Ran 1000 train steps in 106.53 secs\n",
      "Step   3000: train CrossEntropyLoss |  0.94432074\n",
      "Step   3000: eval  CrossEntropyLoss |  1.09890646\n",
      "Step   3000: eval          Accuracy |  0.64437500\n",
      "\n",
      "Step   4000: Ran 1000 train steps in 105.61 secs\n",
      "Step   4000: train CrossEntropyLoss |  0.80568272\n",
      "Step   4000: eval  CrossEntropyLoss |  1.23607775\n",
      "Step   4000: eval          Accuracy |  0.63291667\n",
      "\n",
      "Step   5000: Ran 1000 train steps in 106.80 secs\n",
      "Step   5000: train CrossEntropyLoss |  0.71427822\n",
      "Step   5000: eval  CrossEntropyLoss |  0.89560480\n",
      "Step   5000: eval          Accuracy |  0.71364583\n",
      "\n",
      "Step   6000: Ran 1000 train steps in 106.05 secs\n",
      "Step   6000: train CrossEntropyLoss |  0.64773202\n",
      "Step   6000: eval  CrossEntropyLoss |  0.96779802\n",
      "Step   6000: eval          Accuracy |  0.70989583\n",
      "\n",
      "Step   7000: Ran 1000 train steps in 106.55 secs\n",
      "Step   7000: train CrossEntropyLoss |  0.60432559\n",
      "Step   7000: eval  CrossEntropyLoss |  0.70380987\n",
      "Step   7000: eval          Accuracy |  0.76489583\n",
      "\n",
      "Step   8000: Ran 1000 train steps in 107.08 secs\n",
      "Step   8000: train CrossEntropyLoss |  0.55522698\n",
      "Step   8000: eval  CrossEntropyLoss |  0.76587470\n",
      "Step   8000: eval          Accuracy |  0.75125000\n",
      "\n",
      "Step   9000: Ran 1000 train steps in 105.96 secs\n",
      "Step   9000: train CrossEntropyLoss |  0.53158909\n",
      "Step   9000: eval  CrossEntropyLoss |  0.69913244\n",
      "Step   9000: eval          Accuracy |  0.77208333\n",
      "\n",
      "Step  10000: Ran 1000 train steps in 109.51 secs\n",
      "Step  10000: train CrossEntropyLoss |  0.49183390\n",
      "Step  10000: eval  CrossEntropyLoss |  0.57984877\n",
      "Step  10000: eval          Accuracy |  0.80343750\n",
      "\n",
      "Step  11000: Ran 1000 train steps in 106.10 secs\n",
      "Step  11000: train CrossEntropyLoss |  0.46877530\n",
      "Step  11000: eval  CrossEntropyLoss |  0.48222975\n",
      "Step  11000: eval          Accuracy |  0.83604167\n",
      "\n",
      "Step  12000: Ran 1000 train steps in 107.04 secs\n",
      "Step  12000: train CrossEntropyLoss |  0.43882948\n",
      "Step  12000: eval  CrossEntropyLoss |  0.57474974\n",
      "Step  12000: eval          Accuracy |  0.81218750\n",
      "\n",
      "Step  13000: Ran 1000 train steps in 107.41 secs\n",
      "Step  13000: train CrossEntropyLoss |  0.41691700\n",
      "Step  13000: eval  CrossEntropyLoss |  0.53092413\n",
      "Step  13000: eval          Accuracy |  0.82760417\n",
      "\n",
      "Step  14000: Ran 1000 train steps in 107.03 secs\n",
      "Step  14000: train CrossEntropyLoss |  0.40698951\n",
      "Step  14000: eval  CrossEntropyLoss |  0.59010746\n",
      "Step  14000: eval          Accuracy |  0.80250000\n",
      "\n",
      "Step  15000: Ran 1000 train steps in 108.93 secs\n",
      "Step  15000: train CrossEntropyLoss |  0.38279334\n",
      "Step  15000: eval  CrossEntropyLoss |  0.49296554\n",
      "Step  15000: eval          Accuracy |  0.83458333\n",
      "\n",
      "Step  16000: Ran 1000 train steps in 105.39 secs\n",
      "Step  16000: train CrossEntropyLoss |  0.36752513\n",
      "Step  16000: eval  CrossEntropyLoss |  0.54803635\n",
      "Step  16000: eval          Accuracy |  0.82385417\n",
      "\n",
      "Step  17000: Ran 1000 train steps in 106.26 secs\n",
      "Step  17000: train CrossEntropyLoss |  0.36354846\n",
      "Step  17000: eval  CrossEntropyLoss |  0.46864894\n",
      "Step  17000: eval          Accuracy |  0.84552083\n",
      "\n",
      "Step  18000: Ran 1000 train steps in 107.32 secs\n",
      "Step  18000: train CrossEntropyLoss |  0.34194821\n",
      "Step  18000: eval  CrossEntropyLoss |  0.58723122\n",
      "Step  18000: eval          Accuracy |  0.82062500\n",
      "\n",
      "Step  19000: Ran 1000 train steps in 107.31 secs\n",
      "Step  19000: train CrossEntropyLoss |  0.32466933\n",
      "Step  19000: eval  CrossEntropyLoss |  0.47764196\n",
      "Step  19000: eval          Accuracy |  0.84145833\n",
      "\n",
      "Step  20000: Ran 1000 train steps in 106.91 secs\n",
      "Step  20000: train CrossEntropyLoss |  0.31532502\n",
      "Step  20000: eval  CrossEntropyLoss |  0.49582401\n",
      "Step  20000: eval          Accuracy |  0.83968750\n"
     ]
    }
   ],
   "source": [
    "training_loop.run(NUM_STEPS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
