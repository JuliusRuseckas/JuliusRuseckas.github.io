{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELM on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review of convolutional ELMs:\n",
    "\n",
    "I. R. Rodrigues, S. R. da Silva Neto, J. Kelner, D. Sadok, and P. T. Endo, _Convolutional Extreme Learning Machines: A Systematic Review_, Informatics **8**(2), 33 (2021). https://doi.org/10.3390/informatics8020033 (open access)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='./data'\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_show_image(dset, idx):\n",
    "    X, Y = dset[idx]\n",
    "    title = \"Ground truth: {}\".format(dset.classes[Y])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np.moveaxis(X.numpy(), 0, -1))\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_show_image(test_dset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, classes, image_size, channel_list, in_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        for num, out_channels in enumerate(channel_list):\n",
    "            if num > 0: layers.append(nn.MaxPool2d(2))\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.Tanh()\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        reduced_size = image_size // 2**(len(channel_list) - 1)\n",
    "        self.head = nn.Linear(in_channels * reduced_size**2, classes)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.head(out)\n",
    "        return out\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.normal_(m.bias, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(NUM_CLASSES, IMAGE_SIZE, channel_list = [128, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1,708,426\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters: {:,}\".format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrices(model, loader, classes, device):\n",
    "    HH = 0.\n",
    "    HY = 0.\n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(loader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            \n",
    "            features = model.features(X)\n",
    "            # add ones column for bias:\n",
    "            ones = torch.ones(X.size(0), 1, device=device)\n",
    "            features = torch.cat((features, ones), dim=1)\n",
    "            \n",
    "            HH = HH + features.T @ features\n",
    "            Y_one_hot = F.one_hot(Y, classes)\n",
    "            HY = HY + features.T @ Y_one_hot.float()\n",
    "    \n",
    "    return HH, HY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_linear(HH, HY, device, α=0.):\n",
    "    n = HH.size(0)\n",
    "    HH_reg = HH + α * torch.eye(n, device=DEVICE) # add regularization\n",
    "    sol = torch.linalg.lstsq(HH_reg, HY)\n",
    "    B = sol.solution\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(model, B):\n",
    "    model.head.weight.data = B[:-1].T\n",
    "    model.head.bias.data = B[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, classes, device, α=0.):\n",
    "    HH, HY = create_matrices(model, loader, classes, device)\n",
    "    B = solve_linear(HH, HY, device, α)\n",
    "    update_model(model, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 391/391 [00:04<00:00, 93.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, NUM_CLASSES, DEVICE, α=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            out = model(X)\n",
    "            pred_labels = torch.argmax(out, dim=1)\n",
    "            num_correct += (pred_labels == Y).sum().item()\n",
    "            num_total += X.size(0)\n",
    "    \n",
    "    acc = num_correct / num_total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.638\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, DEVICE)\n",
    "print(f\"Accuracy {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gradient descent: accuracy 0.807"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
